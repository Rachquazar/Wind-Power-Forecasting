{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing of wind turbine data\n",
    "\n",
    "Cells in this notebook can be run independently provided the first two (\"Imports\" and \"Preprocessing function...\") are run first.\n",
    "\n",
    "1. [Imports.](#Cell1)\n",
    "1. [Preprocessing function, good for training data as well as testing data.](#Cell2)\n",
    "1. [Preprocess the training data set, output a pickle file.](#Cell3)\n",
    "1. [Preprocess the training data set in Feather format for notebooks running R kernel.](#Cell4)\n",
    "1. [Preprocess the testing data set, output a pickle file.](#Cell5)\n",
    "1. [Preprocess the testing data set in Feather format for notebooks running R kernel.](#Cell6)\n",
    "1. [Preprocess the solution file (the testing data set with TARGETVAR included). Output in pickle and Feather.](#Cell7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Imports\n",
    "'''\n",
    "import feather\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import strftime\n",
    "import datetime\n",
    "import importlib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocessing function, for training data as well as testing data.\n",
    "'''\n",
    "def preProcess(fname, Nroll=3, keepID=False):\n",
    "    '''\n",
    "    Read in the wind turbine data, store in a Pandas dataframe, and rearrange.\n",
    "\n",
    "    1.  Records in the input csv file are assumed to have the following form:\n",
    "            ID, ZONEID, TIMESTAMP, TARGETVAR, U10, V10, U100, V100\n",
    "        where:\n",
    "            ID =         Unique ID for each observation\n",
    "            ZONEID =     Zone/Turbine ID, a number between 1 and 10\n",
    "            TIMESTAMP =  Time of observation, in the format \"YYYYMMDD h:mm\" or \"YYYYMMDD hh:mm\"\n",
    "            TARGETVAR =  Wind turbine output (only present in the training data set)\n",
    "            U10 =        Zonal Wind Vector at 10 m\n",
    "            V10 =        Meridional Wind Vector at 10 m\n",
    "            U100 =       Zonal Wind vector at 100 m\n",
    "            V100 =       Meridional Wind vector at 100 m\n",
    "    \n",
    "    2. If Nroll<=1, column names in the output data frame have the form:\n",
    "            TARGETVAR U10 V10 U100 V100 YEAR DAYOFYEAR HOUR\n",
    "       and TARGETVAR, U10, V10, U100, V100 each have a subindex 1 ... 10 indicating zone id.\n",
    "       If Nroll>1, the structure is the same, but the U10, V10, U100, V100 columns are replaced\n",
    "       by rolling means over Nroll measurements, and the names are U10_rmX, V10_rmX, U100_rmX, and V100_rmX, where X equals Nroll.\n",
    "    '''\n",
    "\n",
    "    # Read in the windmill data, parsing the third column as datetimes. Make a hierarchical\n",
    "    # index out of the timestamp and zone id columns.  Then drop the measurement ID column.\n",
    "    df0 = pd.read_csv(fname, header=0, parse_dates=[2], index_col=[2,1])\n",
    "    df0.fillna(0, inplace=True)\n",
    "\n",
    "    if not keepID: \n",
    "        df0 = df0.drop('ID', 1)\n",
    "        print('ID column dropped')\n",
    "    else:\n",
    "        print('ID column kept')\n",
    "        \n",
    "    # Unstack the inner level of the index. The index is thus reduced to the timestamp, and \n",
    "    # the zone ids become subcolumns within the existing columns. In other words, where in\n",
    "    # df0 there are 10 rows per time stamp, one for each zone id, in df1 there is only \n",
    "    # 1 row, which contains the measurements made at the given time stamp in all the zone ids.\n",
    "    df1 = df0.unstack()\n",
    "    print ('unstacked')\n",
    "    # Put the timestamp index back as a dataframe column and verify that all delta-times are one hour.\n",
    "    df2              = df1.reset_index()\n",
    "    dtimes           = df2[\"TIMESTAMP\"].subtract(df2[\"TIMESTAMP\"].shift(+1))\n",
    "    Ntimepoints      = len(df2)\n",
    "    #Ndeltatimes1h    = dtimes[dtimes==np.timedelta64(1, 'h')].count()\n",
    "    #assert (Ntimepoints == Ndeltatimes1h+1), 'Delta times not all equal to 1 h!'\n",
    "    #print('Number of time points:                 {0}'.format(Ntimepoints))\n",
    "    #print('Number of delta-times equal to 1 hour: {0}'.format(Ndeltatimes1h))\n",
    "    \n",
    "    # Remove duplicate wind measurements (5 is duplicate with 4, and 8 with 7)\n",
    "    nturbines         = 10\n",
    "    wind_measurements = [1, 2, 3, 4, 6, 7, 9, 10]\n",
    "    for i in range(1,nturbines+1):\n",
    "        if i not in wind_measurements:\n",
    "            df2 = df2.drop([(\"U10\",i), (\"V10\",i), (\"U100\",i), (\"V100\",i)], axis=1)\n",
    "    \n",
    "    # Add rolling means of the wind measurements\n",
    "    if Nroll>1:\n",
    "        print('Computing rolling means over {0} measurements'.format(Nroll))\n",
    "        dname = \"_rm\"+str(Nroll)\n",
    "        for i in wind_measurements:\n",
    "            df2[(\"U10\"+dname,i)]  = df2[(\"U10\",i)].rolling(Nroll, min_periods=1).mean()\n",
    "            df2[(\"U100\"+dname,i)] = df2[(\"U100\",i)].rolling(Nroll, min_periods=1).mean()\n",
    "            df2[(\"V10\"+dname,i)]  = df2[(\"V10\",i)].rolling(Nroll, min_periods=1).mean()\n",
    "            df2[(\"V100\"+dname,i)] = df2[(\"V100\",i)].rolling(Nroll, min_periods=1).mean()\n",
    "    else:\n",
    "        print('No rolling means computed')\n",
    "    \n",
    "    # Extract year, day of year, and hour from timestamp, then drop timestamp column\n",
    "    df2[\"YEAR\"]      = df2[\"TIMESTAMP\"].map(lambda x: x.year)\n",
    "    df2[\"DAYOFYEAR\"] = df2[\"TIMESTAMP\"].map(lambda x: x.timetuple().tm_yday)\n",
    "    df2[\"HOUR\"]      = df2[\"TIMESTAMP\"].map(lambda x: x.hour)\n",
    "    df2              = df2.drop('TIMESTAMP', axis=1, level=0)\n",
    "\n",
    "    return df2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocess the training data set, output a pickle file.\n",
    "'''\n",
    "# Load and preprocess data\n",
    "train_csv = \"Train_O4UPEyW.csv\"\n",
    "train_df  = preProcess(train_csv, Nroll=3, keepID=False)\n",
    "print('\\nDataframe train_df:\\n%s' %train_df.head())\n",
    "\n",
    "# Output dataframe in pickle format\n",
    "\n",
    "train_fname = \"Train_pp_\" + strftime(\"%Y_%m_%d_%H_%M_%S\") + \".pkl\"\n",
    "try:\n",
    "    train_df.to_pickle(train_fname)\n",
    "    print('\\nTraining data frame saved to {0}'.format(train_fname))\n",
    "except:\n",
    "    print('\\nError saving training data frame to {0}'.format(train_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocess the training data set in Feather format for notebooks running R kernel.\n",
    "'''\n",
    "# Load and preprocess data\n",
    "train_csv = \"Train_full.csv\"\n",
    "train_df  = preProcess(train_csv, Nroll=3, keepID=False)\n",
    "\n",
    "# Rename dataframe columns\n",
    "predictors  = [item[0]+'_'+str(item[1]) for item in train_df.columns.values if item[0]!='TARGETVAR']\n",
    "predictors  = [predictor if predictor[-1]!='_' else predictor[:-1] for predictor in predictors]\n",
    "targets     = [item[0]+'_'+str(item[1]) for item in train_df.columns.values if item[0]=='TARGETVAR']\n",
    "train_df.columns = targets+predictors\n",
    "print('\\nDataframe train_df:\\n%s' %train_df.head())\n",
    "\n",
    "# Output data frame in feather format\n",
    "train_fname = \"data/Train_pp_\" + strftime(\"%Y_%m_%d_%H_%M_%S\") + \".feather\"\n",
    "try:\n",
    "    feather.write_dataframe(train_df, train_fname)\n",
    "    print('\\nTraining data frame saved to {0}'.format(train_fname))\n",
    "except:\n",
    "    print('\\nError saving training data frame to {0}'.format(train_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell5'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocess the testing data set, output a pickle file.\n",
    "'''\n",
    "test_csv  = \"data/Test_uP7dymh.csv\"\n",
    "\n",
    "test_df = preProcess(test_csv, Nroll=3, keepID=True)\n",
    "print('\\nDataframe test_df:\\n%s' %test_df.head())\n",
    "\n",
    "test_fname = \"data/Test_pp_\" + strftime(\"%Y_%m_%d_%H_%M_%S\") + \".pkl\"\n",
    "try:\n",
    "    test_df.to_pickle(test_fname)\n",
    "    print('\\nTesting data frame saved to {0}'.format(test_fname))\n",
    "except:\n",
    "    print('\\nError saving testing data frame to {0}'.format(test_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell6'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocess the testing data set in Feather format for notebooks running R kernel.\n",
    "'''\n",
    "test_csv  = \"data/Test_uP7dymh.csv\"\n",
    "\n",
    "test_df = preProcess(test_csv, Nroll=3, keepID=True)\n",
    "\n",
    "# Rename dataframe columns\n",
    "predictors  = [item[0]+'_'+str(item[1]) for item in test_df.columns.values]\n",
    "predictors  = [predictor if predictor[-1]!='_' else predictor[:-1] for predictor in predictors]\n",
    "test_df.columns = predictors\n",
    "print('\\nDataframe test_df:\\n%s' %test_df.head())\n",
    "    \n",
    "# Output data frame in feather format\n",
    "test_fname = \"data/Test_pp_\" + strftime(\"%Y_%m_%d_%H_%M_%S\") + \".feather\"\n",
    "try:\n",
    "    feather.write_dataframe(test_df, test_fname)\n",
    "    print('\\nTesting data frame saved to {0}'.format(test_fname))\n",
    "except:\n",
    "    print('\\nError saving testing data frame to {0}'.format(test_fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Cell7'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Preprocess the solution file. This is the testing data set with TARGETVAR included.\n",
    "Preprocess it in the same way as the training data set, then output it in pickle and feather formats.\n",
    "'''\n",
    "# Load and preprocess data\n",
    "solution_csv = \"data/Solution.csv\"\n",
    "solution_df  = preProcess(solution_csv, Nroll=3, keepID=False)\n",
    "print('\\nDataframe solution_df for pickle:\\n%s' %solution_df.head())\n",
    "\n",
    "# Output dataframe in pickle format\n",
    "fname          = strftime(\"%Y_%m_%d_%H_%M_%S\")\n",
    "solution_fname = \"data/Solution_pp_\" + fname + \".pkl\"\n",
    "try:\n",
    "    solution_df.to_pickle(solution_fname)\n",
    "    print('\\nSolution data frame saved to {0}'.format(solution_fname))\n",
    "except:\n",
    "    print('\\nError saving solution data frame to {0}'.format(solution_fname))\n",
    "    \n",
    "\n",
    "# Rename dataframe columns for easier handling in R\n",
    "fields  = [item[0]+'_'+str(item[1]) for item in solution_df.columns.values]\n",
    "fields  = [field if field[-1]!='_' else field[:-1] for field in fields]\n",
    "solution_df.columns = fields\n",
    "print('\\nDataframe solution_df for feather:\\n%s' %solution_df.head())\n",
    "    \n",
    "# Output data frame in feather format\n",
    "solution_fname = \"data/Solution_pp_\" + fname + \".feather\"\n",
    "try:\n",
    "    feather.write_dataframe(solution_df, solution_fname)\n",
    "    print('\\nSolution data frame saved to {0}'.format(solution_fname))\n",
    "except:\n",
    "    print('\\nError saving solution data frame to {0}'.format(solution_fname))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
